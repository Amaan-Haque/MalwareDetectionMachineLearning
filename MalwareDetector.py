import json
import pandas as pd
import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
import pickle
import sys

# load the model from disk
model = pickle.load(open("static_classifier.sav", 'rb'))

os.chdir(sys.argv[1])
command = "find ./ -name *.json >dynamic_data.txt"
os.system(command)
command = 'find ./ -name Structure_Info.txt > static_data.txt'
os.system(command)


DllCharacteristics_found = False
DebugSize_found = False
ImageVersion_found = False
IatRVA_found = False
ExportSize_found = False
ResourceSize_found = False
NumberOfSections_found = False

hashes = []
DllCharacteristics = []
DebugSize = []
MajorImageVersion = []
MinorImageVersion = []
IatRVA = []
ExportSize = []
ResourceSize = []
NumberOfSections = []


files = open("static_data.txt", "r").read().split('\n')

i =0 
for file_name in files[:-1]:
	# i = i +1
	# print(i)
	# print(file_name)
	hash_name = file_name.split("/")[-2]
	hashes.append(hash_name)
	with open(file_name, errors='ignore') as file:
		# print(file)
		# Found Flags
		# print(file.read())
		DllCharacteristics_found = False
		DebugSize_found = False
		ImageVersion_found = False
		IatRVA_found = False                
		ExportSize_found = False
		ResourceSize_found = False
		NumberOfSections_found = False
		filesize = os.path.getsize(file.name)
		if filesize == 0:
			DllCharacteristics.append(int(0))
			DebugSize.append(int(0))
			MajorImageVersion.append(int(0))
			MinorImageVersion.append(int(0))
			IatRVA.append(int(0))
			ExportSize.append(int(0))
			ResourceSize.append(int(0))
			NumberOfSections.append(int(0))
			continue
		for line in file:
			# print(file_name)
			# print("\n")
			if (DllCharacteristics_found and DebugSize_found and ImageVersion_found and IatRVA_found and ExportSize_found and ResourceSize_found and NumberOfSections_found): break

			if (not DllCharacteristics_found and "DllCharacteristics" in line):
				DllCharacteristics.append(int(line.split(':')[-1].strip(), 16))
				DllCharacteristics_found = True

			if (not DebugSize_found and "IMAGE_DIRECTORY_ENTRY_DEBUG" in line):
				line = next(file)
				line = next(file)
				DebugSize.append(int(line.split(':')[-1].strip(), 16))
				DebugSize_found = True

			# 0x124      0x2C  MajorImageVersion:             0x0       
			# 0x126      0x2E  MinorImageVersion:             0x0  
			if (not ImageVersion_found and "MajorImageVersion" in line):
				line = next(file)
				MajorImageVersion.append(int(line.split(':')[-1].strip(), 16))
				line = next(file)
				MinorImageVersion.append(int(line.split(':')[-1].strip(), 16))
				ImageVersion_found = True

			# [IMAGE_DIRECTORY_ENTRY_IAT]
			# 0x1D8      0x0   VirtualAddress:                0x0       
			# 0x1DC      0x4   Size:                          0x0 
			if (not IatRVA_found and "IMAGE_DIRECTORY_ENTRY_IAT" in line):
				line = next(file)
				IatRVA.append(int(line.split(':')[-1], 16))
				IatRVA_found = True

			# [IMAGE_DIRECTORY_ENTRY_EXPORT]
			# 0x168      0x0   VirtualAddress:                0x0       
			# 0x16C      0x4   Size:                          0x0  
			if (not ExportSize_found and "IMAGE_DIRECTORY_ENTRY_EXPORT" in line):
				line = next(file)
				line = next(file)
				ExportSize.append(int(line.split(':')[-1].strip(), 16))
				ExportSize_found = True

			# [IMAGE_DIRECTORY_ENTRY_RESOURCE]
			# 0x168      0x0   VirtualAddress:                0x0       
			# 0x16C      0x4   Size:                          0x0  
			if (not ResourceSize_found and "IMAGE_DIRECTORY_ENTRY_RESOURCE" in line):
				line = next(file)
				line = next(file)
				ResourceSize.append(int(line.split(':')[-1].strip(), 16))
				ResourceSize_found = True

			# [IMAGE_FILE_HEADER]
			# 0x84       0x0   Machine:                       0x14C     
			# 0x86       0x2   NumberOfSections:              0xA     
			if (not NumberOfSections_found and "IMAGE_FILE_HEADER" in line):
				line = next(file)
				line = next(file)
				NumberOfSections.append(int(line.split(':')[-1].strip(), 16))
				NumberOfSections_found = True

		if(not DllCharacteristics_found):
			DllCharacteristics.append(int(0))

		if(not DebugSize_found):
			DebugSize.append(int(0))

		if(not ImageVersion_found):
			MajorImageVersion.append(int(0))
			MinorImageVersion.append(int(0))

		if(not IatRVA_found):
			IatRVA.append(int(0))

		if(not ExportSize_found):
			ExportSize.append(int(0))

		if(not ResourceSize_found):
			ResourceSize.append(int(0))

		if(not NumberOfSections_found):
			NumberOfSections.append(int(0))



df = pd.DataFrame({'hash' : hashes, 'DllCharacteristics' : DllCharacteristics, 'DebugSize' : DebugSize, 'MajorImageVersion': MajorImageVersion, 'MinorImageVersion' : MinorImageVersion, 'IatRVA' : IatRVA, 'ExportSize' : ExportSize, 'ResourceSize' : ResourceSize, 'NumberOfSections' : NumberOfSections})

df.to_csv("testing.csv")


#================================================================================
#================================CLASSIFICATION==================================
#================================================================================

df = pd.read_csv('testing.csv')

X = df.drop(['hash'], axis=1).values
# y = df.drop(['hash', 'DllCharacteristics', 'DebugSize', 'MajorImageVersion', 'MinorImageVersion', 'IatRVA', 'ExportSize', 'ResourceSize', 'NumberOfSections'], axis=1).values


# drop 1st column
X = X[:, 1:]
# y = y[:, 1:]

# convert dtype to int
X = X.astype(int)
# y = y.astype(int)

# X_train, X_test, y_train, y_test = train_test_split(X, y)

#  == PREPROCESSING ==
scaler = StandardScaler()
scaler.fit(X)
X_scaled = scaler.transform(X)

# # == CLASSIFICATION ==
y_pred = model.predict(X_scaled)

prediction_column = []
for i in y_pred:
	if (i == 0):
		prediction_column.append('malware')
	else:
		prediction_column.append('benign')

df_classification = pd.DataFrame({'hash' : hashes, 'prediction' : prediction_column})
print("Output in FINAL_DOC.csv")
df_classification.to_csv('FINAL_DOCc.csv')

# Project must have good accuracy, precision, recall, and F-score for both machine learning 
# models (Static and Dynamic analysis) with low false positive and low false negative rate._
